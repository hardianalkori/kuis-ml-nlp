{
 "cells": [
  {
   "cell_type": "raw",
   "id": "3c28f61d",
   "metadata": {},
   "source": [
    "NAMA: Hardian Alkori\n",
    "NIM: 20102153\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2786ad41",
   "metadata": {},
   "source": [
    "# SOAL NO 1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d3ba0138",
   "metadata": {},
   "source": [
    "1.Sebagai system pendukung keputusan untuk seleksi calon penerima beasiswa\n",
    "Dalam penggunaanya model yang dibangun menggunakan model machine learning yang dimana untuk mendukung keputusan nya\n",
    "dapat dihitung dari golongan gaji,rentang nilai tiap semester, dan lainya yang akan menghasilkan output calon penerima tersebut\n",
    "layak atau tidak.\n",
    "\n",
    "2.Penghasil karya seni gambar\n",
    "Model machine learning sekarang dapat menghasilkan karya seni berupa gambar yang dimana user hanya\n",
    "mengetikan prompt seperti “wanita,background gedung,berambut pirang” maka sebuah model machine learning dapat menghasilkan\n",
    "lukisan/gambar yang sesuai dengan prompt yang di inputkan oleh user.\n",
    "\n",
    "3.3. Sebagai diagnose sebuah penyakit\n",
    "Dengan model machine learning yang telah dibangun, model yang dibangun dapat mendiagnosa sebuah penyakit\n",
    "berdasarkan parameter yang ada, dari parameter yang ada selanjutnya akan diproses tahap perhitungan menggunakan\n",
    "algoritma yang ada dan menghasilkan output pasien tersebut terdampak penyakit atau tidak.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e26ffa4a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>x14</th>\n",
       "      <th>x15</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3181138696723953</td>\n",
       "      <td>0.817627956963529</td>\n",
       "      <td>0.4781069798001085</td>\n",
       "      <td>0.9594544104761595</td>\n",
       "      <td>0.6423578882170318</td>\n",
       "      <td>0.452872741438477</td>\n",
       "      <td>0.776778297910482</td>\n",
       "      <td>0.028347175937025737</td>\n",
       "      <td>0.8714641906456886</td>\n",
       "      <td>0.0033710898171540604</td>\n",
       "      <td>0.8086471789532645</td>\n",
       "      <td>0.9259306868571727</td>\n",
       "      <td>0.010487883328595848</td>\n",
       "      <td>0.7233206705589501</td>\n",
       "      <td>0.9781878760830326</td>\n",
       "      <td>12.643120040829338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5090371318254673</td>\n",
       "      <td>0.9050927148828956</td>\n",
       "      <td>0.029437542808689154</td>\n",
       "      <td>0.9510637484497582</td>\n",
       "      <td>0.8510868953736089</td>\n",
       "      <td>0.9958333686347052</td>\n",
       "      <td>0.9585879554264608</td>\n",
       "      <td>0.6539224937308654</td>\n",
       "      <td>0.06105563011799586</td>\n",
       "      <td>0.12926391954588923</td>\n",
       "      <td>0.22657380220974</td>\n",
       "      <td>0.45475160988776986</td>\n",
       "      <td>0.5377414444185367</td>\n",
       "      <td>0.08626728914605064</td>\n",
       "      <td>0.34943395752348394</td>\n",
       "      <td>3.5309590153370323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8102705410743646</td>\n",
       "      <td>0.8769711821373619</td>\n",
       "      <td>0.22478627116074068</td>\n",
       "      <td>0.8024469354671377</td>\n",
       "      <td>0.7484397264940142</td>\n",
       "      <td>0.39092747967621533</td>\n",
       "      <td>0.9986088299726693</td>\n",
       "      <td>0.9596261301547352</td>\n",
       "      <td>0.25643776084377023</td>\n",
       "      <td>0.27669530583636426</td>\n",
       "      <td>0.30396394414740724</td>\n",
       "      <td>0.037176568477376826</td>\n",
       "      <td>0.20101065302285348</td>\n",
       "      <td>0.9029609041271385</td>\n",
       "      <td>0.928176507990674</td>\n",
       "      <td>9.894654695348283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3769550103989885</td>\n",
       "      <td>0.4459937473260053</td>\n",
       "      <td>0.11814285210178899</td>\n",
       "      <td>0.5869993048849421</td>\n",
       "      <td>0.6499650074293872</td>\n",
       "      <td>0.09657903313696559</td>\n",
       "      <td>0.9883045110074741</td>\n",
       "      <td>0.049375959400466685</td>\n",
       "      <td>0.06493988526475825</td>\n",
       "      <td>0.7911640939319076</td>\n",
       "      <td>0.8600313823258994</td>\n",
       "      <td>0.4802246476306399</td>\n",
       "      <td>0.8584643342530005</td>\n",
       "      <td>0.7482952130458684</td>\n",
       "      <td>0.41759131005916816</td>\n",
       "      <td>1.3788903744282028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8536175353237497</td>\n",
       "      <td>0.8157810705594152</td>\n",
       "      <td>0.7473514233552918</td>\n",
       "      <td>0.3961359006603382</td>\n",
       "      <td>0.7452528230723602</td>\n",
       "      <td>0.6439464266041328</td>\n",
       "      <td>0.8953922901997936</td>\n",
       "      <td>0.5725497207862202</td>\n",
       "      <td>0.9226988509324736</td>\n",
       "      <td>0.40087898504909125</td>\n",
       "      <td>0.8963444703503332</td>\n",
       "      <td>0.8584997492736304</td>\n",
       "      <td>0.4141265617033547</td>\n",
       "      <td>0.8685056475102194</td>\n",
       "      <td>0.9332323507446865</td>\n",
       "      <td>9.615164357812361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>0.5761465271106402</td>\n",
       "      <td>0.7467487932052328</td>\n",
       "      <td>0.23060060843578434</td>\n",
       "      <td>0.9488147638949792</td>\n",
       "      <td>0.5189764391690906</td>\n",
       "      <td>0.5707826106441647</td>\n",
       "      <td>0.16310738803098934</td>\n",
       "      <td>0.7041517949882347</td>\n",
       "      <td>0.7539670306394566</td>\n",
       "      <td>0.8642344398083646</td>\n",
       "      <td>0.02440077219283321</td>\n",
       "      <td>0.35036655746784284</td>\n",
       "      <td>0.2536573928585838</td>\n",
       "      <td>0.07996375902865238</td>\n",
       "      <td>0.84106911961038</td>\n",
       "      <td>3.818415589257154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>0.24784421396856882</td>\n",
       "      <td>0.15872698536990792</td>\n",
       "      <td>0.6275634114722108</td>\n",
       "      <td>0.254202563210437</td>\n",
       "      <td>0.8106009216370522</td>\n",
       "      <td>0.6888923356685105</td>\n",
       "      <td>0.06186733388157151</td>\n",
       "      <td>0.05373643648660986</td>\n",
       "      <td>0.6876106168678394</td>\n",
       "      <td>0.12905519969513346</td>\n",
       "      <td>0.9146235655442672</td>\n",
       "      <td>0.6799600032164606</td>\n",
       "      <td>0.4187458959484537</td>\n",
       "      <td>0.18589905121166328</td>\n",
       "      <td>0.8630948206675576</td>\n",
       "      <td>8.344037194202764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>0.28207969099510455</td>\n",
       "      <td>0.8805119730238093</td>\n",
       "      <td>0.8534964812117797</td>\n",
       "      <td>0.15620409881466424</td>\n",
       "      <td>0.19064146095180579</td>\n",
       "      <td>0.4298840425174245</td>\n",
       "      <td>0.5597119229071036</td>\n",
       "      <td>0.96508704407317</td>\n",
       "      <td>0.34449012436358173</td>\n",
       "      <td>0.4806460372235688</td>\n",
       "      <td>0.056571516031907576</td>\n",
       "      <td>0.897595566163169</td>\n",
       "      <td>0.015407313959026836</td>\n",
       "      <td>0.4301685670269343</td>\n",
       "      <td>0.07851740182141165</td>\n",
       "      <td>2.4883615832509647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>0.7217615232638763</td>\n",
       "      <td>0.8798093034037527</td>\n",
       "      <td>0.6103470200374284</td>\n",
       "      <td>0.9553716914113278</td>\n",
       "      <td>0.17058355778345635</td>\n",
       "      <td>0.37951699384121473</td>\n",
       "      <td>0.7326559999457845</td>\n",
       "      <td>0.38709913460736534</td>\n",
       "      <td>0.7775411513085453</td>\n",
       "      <td>0.3933725866795855</td>\n",
       "      <td>0.40280593243722795</td>\n",
       "      <td>0.8588491082944556</td>\n",
       "      <td>0.03850460630777597</td>\n",
       "      <td>0.20433784851690195</td>\n",
       "      <td>0.04304661444893354</td>\n",
       "      <td>3.5771304721492156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>0.7691111880056888</td>\n",
       "      <td>0.37068026219918915</td>\n",
       "      <td>0.6700936991451084</td>\n",
       "      <td>0.7795178062823193</td>\n",
       "      <td>0.9024514338686945</td>\n",
       "      <td>0.9997621086217271</td>\n",
       "      <td>0.28582161461496747</td>\n",
       "      <td>0.054683950209623355</td>\n",
       "      <td>0.42921736858547177</td>\n",
       "      <td>0.7466320476621817</td>\n",
       "      <td>0.11230611757763176</td>\n",
       "      <td>0.4521600858048509</td>\n",
       "      <td>0.02409367924560546</td>\n",
       "      <td>0.2520503589401528</td>\n",
       "      <td>0.023716977751510826</td>\n",
       "      <td>-2.464825620973439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      x1                   x2                    x3  \\\n",
       "0     0.3181138696723953    0.817627956963529    0.4781069798001085   \n",
       "1     0.5090371318254673   0.9050927148828956  0.029437542808689154   \n",
       "2     0.8102705410743646   0.8769711821373619   0.22478627116074068   \n",
       "3     0.3769550103989885   0.4459937473260053   0.11814285210178899   \n",
       "4     0.8536175353237497   0.8157810705594152    0.7473514233552918   \n",
       "..                   ...                  ...                   ...   \n",
       "895   0.5761465271106402   0.7467487932052328   0.23060060843578434   \n",
       "896  0.24784421396856882  0.15872698536990792    0.6275634114722108   \n",
       "897  0.28207969099510455   0.8805119730238093    0.8534964812117797   \n",
       "898   0.7217615232638763   0.8798093034037527    0.6103470200374284   \n",
       "899   0.7691111880056888  0.37068026219918915    0.6700936991451084   \n",
       "\n",
       "                      x4                   x5                   x6  \\\n",
       "0     0.9594544104761595   0.6423578882170318    0.452872741438477   \n",
       "1     0.9510637484497582   0.8510868953736089   0.9958333686347052   \n",
       "2     0.8024469354671377   0.7484397264940142  0.39092747967621533   \n",
       "3     0.5869993048849421   0.6499650074293872  0.09657903313696559   \n",
       "4     0.3961359006603382   0.7452528230723602   0.6439464266041328   \n",
       "..                   ...                  ...                  ...   \n",
       "895   0.9488147638949792   0.5189764391690906   0.5707826106441647   \n",
       "896    0.254202563210437   0.8106009216370522   0.6888923356685105   \n",
       "897  0.15620409881466424  0.19064146095180579   0.4298840425174245   \n",
       "898   0.9553716914113278  0.17058355778345635  0.37951699384121473   \n",
       "899   0.7795178062823193   0.9024514338686945   0.9997621086217271   \n",
       "\n",
       "                      x7                    x8                   x9  \\\n",
       "0      0.776778297910482  0.028347175937025737   0.8714641906456886   \n",
       "1     0.9585879554264608    0.6539224937308654  0.06105563011799586   \n",
       "2     0.9986088299726693    0.9596261301547352  0.25643776084377023   \n",
       "3     0.9883045110074741  0.049375959400466685  0.06493988526475825   \n",
       "4     0.8953922901997936    0.5725497207862202   0.9226988509324736   \n",
       "..                   ...                   ...                  ...   \n",
       "895  0.16310738803098934    0.7041517949882347   0.7539670306394566   \n",
       "896  0.06186733388157151   0.05373643648660986   0.6876106168678394   \n",
       "897   0.5597119229071036      0.96508704407317  0.34449012436358173   \n",
       "898   0.7326559999457845   0.38709913460736534   0.7775411513085453   \n",
       "899  0.28582161461496747  0.054683950209623355  0.42921736858547177   \n",
       "\n",
       "                       x10                   x11                   x12  \\\n",
       "0    0.0033710898171540604    0.8086471789532645    0.9259306868571727   \n",
       "1      0.12926391954588923      0.22657380220974   0.45475160988776986   \n",
       "2      0.27669530583636426   0.30396394414740724  0.037176568477376826   \n",
       "3       0.7911640939319076    0.8600313823258994    0.4802246476306399   \n",
       "4      0.40087898504909125    0.8963444703503332    0.8584997492736304   \n",
       "..                     ...                   ...                   ...   \n",
       "895     0.8642344398083646   0.02440077219283321   0.35036655746784284   \n",
       "896    0.12905519969513346    0.9146235655442672    0.6799600032164606   \n",
       "897     0.4806460372235688  0.056571516031907576     0.897595566163169   \n",
       "898     0.3933725866795855   0.40280593243722795    0.8588491082944556   \n",
       "899     0.7466320476621817   0.11230611757763176    0.4521600858048509   \n",
       "\n",
       "                      x13                  x14                   x15  \\\n",
       "0    0.010487883328595848   0.7233206705589501    0.9781878760830326   \n",
       "1      0.5377414444185367  0.08626728914605064   0.34943395752348394   \n",
       "2     0.20101065302285348   0.9029609041271385     0.928176507990674   \n",
       "3      0.8584643342530005   0.7482952130458684   0.41759131005916816   \n",
       "4      0.4141265617033547   0.8685056475102194    0.9332323507446865   \n",
       "..                    ...                  ...                   ...   \n",
       "895    0.2536573928585838  0.07996375902865238      0.84106911961038   \n",
       "896    0.4187458959484537  0.18589905121166328    0.8630948206675576   \n",
       "897  0.015407313959026836   0.4301685670269343   0.07851740182141165   \n",
       "898   0.03850460630777597  0.20433784851690195   0.04304661444893354   \n",
       "899   0.02409367924560546   0.2520503589401528  0.023716977751510826   \n",
       "\n",
       "                      y  \n",
       "0    12.643120040829338  \n",
       "1    3.5309590153370323  \n",
       "2     9.894654695348283  \n",
       "3    1.3788903744282028  \n",
       "4     9.615164357812361  \n",
       "..                  ...  \n",
       "895   3.818415589257154  \n",
       "896   8.344037194202764  \n",
       "897  2.4883615832509647  \n",
       "898  3.5771304721492156  \n",
       "899  -2.464825620973439  \n",
       "\n",
       "[900 rows x 16 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load dataset menggunakan pandas dengan mendefinisikan koma pada nilai yang ada menggunakan tanda koma\n",
    "df = pd.read_csv(\"UTS_train.csv\", decimal = \",\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c988e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merubah nilai pada dataset menjadi float\n",
    "df = df.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8dd4ad44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# melakukan pendefinisian variabel dimana input merupakan x1-x15 dan y nya adalah kolom y\n",
    "data = df.values\n",
    "\n",
    "x = data[:,:-1]\n",
    "y = data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a6837037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_373 (Dense)           (None, 100)               1600      \n",
      "                                                                 \n",
      " dense_374 (Dense)           (None, 200)               20200     \n",
      "                                                                 \n",
      " dense_375 (Dense)           (None, 300)               60300     \n",
      "                                                                 \n",
      " flatten_47 (Flatten)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_376 (Dense)           (None, 50)                15050     \n",
      "                                                                 \n",
      " dense_377 (Dense)           (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_378 (Dense)           (None, 6)                 156       \n",
      "                                                                 \n",
      " dense_379 (Dense)           (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,588\n",
      "Trainable params: 98,588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# mendesain MLP untuk training\n",
    "    \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten,Dropout\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(100, input_dim = 15, activation = \"relu\")) \n",
    "model.add(Dense(200, activation = \"relu\"))\n",
    "model.add(Dense(300, activation = \"relu\")) \n",
    "model.add(Flatten()) \n",
    "model.add(Dense(50, activation = \"relu\"))\n",
    "model.add(Dense(25, activation = \"relu\"))\n",
    "#model.add(Dense(12, activation = \"relu\"))\n",
    "model.add(Dense(6, activation = \"relu\"))\n",
    "model.add(Dense(1, activation = \"linear\")) \n",
    "model.compile(loss = \"mean_absolute_error\",optimizer = \"adam\", metrics=[\"mean_absolute_error\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "60a912f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 3.0251 - mean_absolute_error: 3.0251 - val_loss: 2.1318 - val_mean_absolute_error: 2.1318\n",
      "Epoch 2/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 1.5384 - mean_absolute_error: 1.5384 - val_loss: 1.4850 - val_mean_absolute_error: 1.4850\n",
      "Epoch 3/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.9271 - mean_absolute_error: 0.9271 - val_loss: 0.8991 - val_mean_absolute_error: 0.8991\n",
      "Epoch 4/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.7961 - mean_absolute_error: 0.7961 - val_loss: 0.7628 - val_mean_absolute_error: 0.7628\n",
      "Epoch 5/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.7070 - mean_absolute_error: 0.7070 - val_loss: 0.7158 - val_mean_absolute_error: 0.7158\n",
      "Epoch 6/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.6673 - mean_absolute_error: 0.6673 - val_loss: 0.6707 - val_mean_absolute_error: 0.6707\n",
      "Epoch 7/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.6060 - mean_absolute_error: 0.6060 - val_loss: 0.6114 - val_mean_absolute_error: 0.6114\n",
      "Epoch 8/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.5648 - mean_absolute_error: 0.5648 - val_loss: 0.5747 - val_mean_absolute_error: 0.5747\n",
      "Epoch 9/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.4943 - mean_absolute_error: 0.4943 - val_loss: 0.5337 - val_mean_absolute_error: 0.5337\n",
      "Epoch 10/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.4401 - mean_absolute_error: 0.4401 - val_loss: 0.5414 - val_mean_absolute_error: 0.5414\n",
      "Epoch 11/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.4600 - mean_absolute_error: 0.4600 - val_loss: 0.3977 - val_mean_absolute_error: 0.3977\n",
      "Epoch 12/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.3935 - mean_absolute_error: 0.3935 - val_loss: 0.4544 - val_mean_absolute_error: 0.4544\n",
      "Epoch 13/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.3643 - mean_absolute_error: 0.3643 - val_loss: 0.4189 - val_mean_absolute_error: 0.4189\n",
      "Epoch 14/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.3552 - mean_absolute_error: 0.3552 - val_loss: 0.4257 - val_mean_absolute_error: 0.4257\n",
      "Epoch 15/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.3592 - mean_absolute_error: 0.3592 - val_loss: 0.4282 - val_mean_absolute_error: 0.4282\n",
      "Epoch 16/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.2856 - mean_absolute_error: 0.2856 - val_loss: 0.3385 - val_mean_absolute_error: 0.3385\n",
      "Epoch 17/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.2862 - mean_absolute_error: 0.2862 - val_loss: 0.3630 - val_mean_absolute_error: 0.3630\n",
      "Epoch 18/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.3215 - mean_absolute_error: 0.3215 - val_loss: 0.4117 - val_mean_absolute_error: 0.4117\n",
      "Epoch 19/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.2781 - mean_absolute_error: 0.2781 - val_loss: 0.4062 - val_mean_absolute_error: 0.4062\n",
      "Epoch 20/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.2974 - mean_absolute_error: 0.2974 - val_loss: 0.3318 - val_mean_absolute_error: 0.3318\n",
      "Epoch 21/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.2778 - mean_absolute_error: 0.2778 - val_loss: 0.3181 - val_mean_absolute_error: 0.3181\n",
      "Epoch 22/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.2502 - mean_absolute_error: 0.2502 - val_loss: 0.3614 - val_mean_absolute_error: 0.3614\n",
      "Epoch 23/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.2653 - mean_absolute_error: 0.2653 - val_loss: 0.3267 - val_mean_absolute_error: 0.3267\n",
      "Epoch 24/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.2557 - mean_absolute_error: 0.2557 - val_loss: 0.3065 - val_mean_absolute_error: 0.3065\n",
      "Epoch 25/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.2739 - mean_absolute_error: 0.2739 - val_loss: 0.3313 - val_mean_absolute_error: 0.3313\n",
      "Epoch 26/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.2450 - mean_absolute_error: 0.2450 - val_loss: 0.3356 - val_mean_absolute_error: 0.3356\n",
      "Epoch 27/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.2701 - mean_absolute_error: 0.2701 - val_loss: 0.3230 - val_mean_absolute_error: 0.3230\n",
      "Epoch 28/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.2421 - mean_absolute_error: 0.2421 - val_loss: 0.3075 - val_mean_absolute_error: 0.3075\n",
      "Epoch 29/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.2371 - mean_absolute_error: 0.2371 - val_loss: 0.3965 - val_mean_absolute_error: 0.3965\n",
      "Epoch 30/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.2237 - mean_absolute_error: 0.2237 - val_loss: 0.2938 - val_mean_absolute_error: 0.2938\n",
      "Epoch 31/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.2271 - mean_absolute_error: 0.2271 - val_loss: 0.2961 - val_mean_absolute_error: 0.2961\n",
      "Epoch 32/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.2181 - mean_absolute_error: 0.2181 - val_loss: 0.4121 - val_mean_absolute_error: 0.4121\n",
      "Epoch 33/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1866 - mean_absolute_error: 0.1866 - val_loss: 0.2950 - val_mean_absolute_error: 0.2950\n",
      "Epoch 34/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.2183 - mean_absolute_error: 0.2183 - val_loss: 0.2876 - val_mean_absolute_error: 0.2876\n",
      "Epoch 35/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.2306 - mean_absolute_error: 0.2306 - val_loss: 0.2784 - val_mean_absolute_error: 0.2784\n",
      "Epoch 36/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.2288 - mean_absolute_error: 0.2288 - val_loss: 0.3237 - val_mean_absolute_error: 0.3237\n",
      "Epoch 37/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.2113 - mean_absolute_error: 0.2113 - val_loss: 0.2907 - val_mean_absolute_error: 0.2907\n",
      "Epoch 38/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1733 - mean_absolute_error: 0.1733 - val_loss: 0.2718 - val_mean_absolute_error: 0.2718\n",
      "Epoch 39/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1946 - mean_absolute_error: 0.1946 - val_loss: 0.2995 - val_mean_absolute_error: 0.2995\n",
      "Epoch 40/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.2087 - mean_absolute_error: 0.2087 - val_loss: 0.2785 - val_mean_absolute_error: 0.2785\n",
      "Epoch 41/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.2062 - mean_absolute_error: 0.2062 - val_loss: 0.2758 - val_mean_absolute_error: 0.2758\n",
      "Epoch 42/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1912 - mean_absolute_error: 0.1912 - val_loss: 0.2985 - val_mean_absolute_error: 0.2985\n",
      "Epoch 43/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.2157 - mean_absolute_error: 0.2157 - val_loss: 0.2688 - val_mean_absolute_error: 0.2688\n",
      "Epoch 44/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.2438 - mean_absolute_error: 0.2438 - val_loss: 0.3005 - val_mean_absolute_error: 0.3005\n",
      "Epoch 45/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.2075 - mean_absolute_error: 0.2075 - val_loss: 0.3264 - val_mean_absolute_error: 0.3264\n",
      "Epoch 46/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.2111 - mean_absolute_error: 0.2111 - val_loss: 0.3097 - val_mean_absolute_error: 0.3097\n",
      "Epoch 47/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1830 - mean_absolute_error: 0.1830 - val_loss: 0.2872 - val_mean_absolute_error: 0.2872\n",
      "Epoch 48/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1801 - mean_absolute_error: 0.1801 - val_loss: 0.2798 - val_mean_absolute_error: 0.2798\n",
      "Epoch 49/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1692 - mean_absolute_error: 0.1692 - val_loss: 0.2942 - val_mean_absolute_error: 0.2942\n",
      "Epoch 50/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1906 - mean_absolute_error: 0.1906 - val_loss: 0.2831 - val_mean_absolute_error: 0.2831\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1991 - mean_absolute_error: 0.1991 - val_loss: 0.2508 - val_mean_absolute_error: 0.2508\n",
      "Epoch 52/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1749 - mean_absolute_error: 0.1749 - val_loss: 0.2716 - val_mean_absolute_error: 0.2716\n",
      "Epoch 53/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1942 - mean_absolute_error: 0.1942 - val_loss: 0.3141 - val_mean_absolute_error: 0.3141\n",
      "Epoch 54/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1916 - mean_absolute_error: 0.1916 - val_loss: 0.2768 - val_mean_absolute_error: 0.2768\n",
      "Epoch 55/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1558 - mean_absolute_error: 0.1558 - val_loss: 0.3940 - val_mean_absolute_error: 0.3940\n",
      "Epoch 56/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.2022 - mean_absolute_error: 0.2022 - val_loss: 0.2832 - val_mean_absolute_error: 0.2832\n",
      "Epoch 57/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1470 - mean_absolute_error: 0.1470 - val_loss: 0.2645 - val_mean_absolute_error: 0.2645\n",
      "Epoch 58/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1679 - mean_absolute_error: 0.1679 - val_loss: 0.2713 - val_mean_absolute_error: 0.2713\n",
      "Epoch 59/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1927 - mean_absolute_error: 0.1927 - val_loss: 0.3316 - val_mean_absolute_error: 0.3316\n",
      "Epoch 60/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1898 - mean_absolute_error: 0.1898 - val_loss: 0.2694 - val_mean_absolute_error: 0.2694\n",
      "Epoch 61/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1900 - mean_absolute_error: 0.1900 - val_loss: 0.2750 - val_mean_absolute_error: 0.2750\n",
      "Epoch 62/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1551 - mean_absolute_error: 0.1551 - val_loss: 0.2848 - val_mean_absolute_error: 0.2848\n",
      "Epoch 63/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1598 - mean_absolute_error: 0.1598 - val_loss: 0.2841 - val_mean_absolute_error: 0.2841\n",
      "Epoch 64/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1569 - mean_absolute_error: 0.1569 - val_loss: 0.2577 - val_mean_absolute_error: 0.2577\n",
      "Epoch 65/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1451 - mean_absolute_error: 0.1451 - val_loss: 0.2480 - val_mean_absolute_error: 0.2480\n",
      "Epoch 66/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1725 - mean_absolute_error: 0.1725 - val_loss: 0.2621 - val_mean_absolute_error: 0.2621\n",
      "Epoch 67/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1474 - mean_absolute_error: 0.1474 - val_loss: 0.2420 - val_mean_absolute_error: 0.2420\n",
      "Epoch 68/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1406 - mean_absolute_error: 0.1406 - val_loss: 0.2571 - val_mean_absolute_error: 0.2571\n",
      "Epoch 69/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1513 - mean_absolute_error: 0.1513 - val_loss: 0.2717 - val_mean_absolute_error: 0.2717\n",
      "Epoch 70/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1711 - mean_absolute_error: 0.1711 - val_loss: 0.2562 - val_mean_absolute_error: 0.2562\n",
      "Epoch 71/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1367 - mean_absolute_error: 0.1367 - val_loss: 0.2661 - val_mean_absolute_error: 0.2661\n",
      "Epoch 72/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1428 - mean_absolute_error: 0.1428 - val_loss: 0.2628 - val_mean_absolute_error: 0.2628\n",
      "Epoch 73/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1480 - mean_absolute_error: 0.1480 - val_loss: 0.2948 - val_mean_absolute_error: 0.2948\n",
      "Epoch 74/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.2278 - mean_absolute_error: 0.2278 - val_loss: 0.2589 - val_mean_absolute_error: 0.2589\n",
      "Epoch 75/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1370 - mean_absolute_error: 0.1370 - val_loss: 0.2747 - val_mean_absolute_error: 0.2747\n",
      "Epoch 76/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1628 - mean_absolute_error: 0.1628 - val_loss: 0.3050 - val_mean_absolute_error: 0.3050\n",
      "Epoch 77/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1354 - mean_absolute_error: 0.1354 - val_loss: 0.2742 - val_mean_absolute_error: 0.2742\n",
      "Epoch 78/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1299 - mean_absolute_error: 0.1299 - val_loss: 0.2554 - val_mean_absolute_error: 0.2554\n",
      "Epoch 79/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1198 - mean_absolute_error: 0.1198 - val_loss: 0.2908 - val_mean_absolute_error: 0.2908\n",
      "Epoch 80/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1424 - mean_absolute_error: 0.1424 - val_loss: 0.2495 - val_mean_absolute_error: 0.2495\n",
      "Epoch 81/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1602 - mean_absolute_error: 0.1602 - val_loss: 0.3394 - val_mean_absolute_error: 0.3394\n",
      "Epoch 82/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1266 - mean_absolute_error: 0.1266 - val_loss: 0.2890 - val_mean_absolute_error: 0.2890\n",
      "Epoch 83/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1278 - mean_absolute_error: 0.1278 - val_loss: 0.2622 - val_mean_absolute_error: 0.2622\n",
      "Epoch 84/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1717 - mean_absolute_error: 0.1717 - val_loss: 0.2495 - val_mean_absolute_error: 0.2495\n",
      "Epoch 85/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1367 - mean_absolute_error: 0.1367 - val_loss: 0.2454 - val_mean_absolute_error: 0.2454\n",
      "Epoch 86/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1235 - mean_absolute_error: 0.1235 - val_loss: 0.2552 - val_mean_absolute_error: 0.2552\n",
      "Epoch 87/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1267 - mean_absolute_error: 0.1267 - val_loss: 0.2741 - val_mean_absolute_error: 0.2741\n",
      "Epoch 88/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1469 - mean_absolute_error: 0.1469 - val_loss: 0.2832 - val_mean_absolute_error: 0.2832\n",
      "Epoch 89/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1778 - mean_absolute_error: 0.1778 - val_loss: 0.3250 - val_mean_absolute_error: 0.3250\n",
      "Epoch 90/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1855 - mean_absolute_error: 0.1855 - val_loss: 0.2811 - val_mean_absolute_error: 0.2811\n",
      "Epoch 91/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1418 - mean_absolute_error: 0.1418 - val_loss: 0.2375 - val_mean_absolute_error: 0.2375\n",
      "Epoch 92/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1458 - mean_absolute_error: 0.1458 - val_loss: 0.2479 - val_mean_absolute_error: 0.2479\n",
      "Epoch 93/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1201 - mean_absolute_error: 0.1201 - val_loss: 0.2512 - val_mean_absolute_error: 0.2512\n",
      "Epoch 94/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1196 - mean_absolute_error: 0.1196 - val_loss: 0.2603 - val_mean_absolute_error: 0.2603\n",
      "Epoch 95/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1192 - mean_absolute_error: 0.1192 - val_loss: 0.2424 - val_mean_absolute_error: 0.2424\n",
      "Epoch 96/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1210 - mean_absolute_error: 0.1210 - val_loss: 0.2460 - val_mean_absolute_error: 0.2460\n",
      "Epoch 97/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1234 - mean_absolute_error: 0.1234 - val_loss: 0.2659 - val_mean_absolute_error: 0.2659\n",
      "Epoch 98/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1318 - mean_absolute_error: 0.1318 - val_loss: 0.2494 - val_mean_absolute_error: 0.2494\n",
      "Epoch 99/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1446 - mean_absolute_error: 0.1446 - val_loss: 0.2467 - val_mean_absolute_error: 0.2467\n",
      "Epoch 100/100\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.1695 - mean_absolute_error: 0.1695 - val_loss: 0.2818 - val_mean_absolute_error: 0.2818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27a979b2940>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#melakukan training dengan btach size sebanyak 1 dan epochs sebanyak 100 kali dengan validation 10%\n",
    "model.fit(x,y, batch_size = 10, epochs = 100, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7593d599",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>x14</th>\n",
       "      <th>x15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7279463652879037</td>\n",
       "      <td>0.6866263027974453</td>\n",
       "      <td>0.024216355151086222</td>\n",
       "      <td>0.10051346797223315</td>\n",
       "      <td>0.14790184117738137</td>\n",
       "      <td>0.6651574435679946</td>\n",
       "      <td>0.8865782074527322</td>\n",
       "      <td>0.2602098404854192</td>\n",
       "      <td>0.9135359850986395</td>\n",
       "      <td>0.429280624808031</td>\n",
       "      <td>0.3863064875506751</td>\n",
       "      <td>0.4297454335327542</td>\n",
       "      <td>0.3430209147301143</td>\n",
       "      <td>0.8642878816290207</td>\n",
       "      <td>0.6974519811249746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9410291805105507</td>\n",
       "      <td>0.7548015847155811</td>\n",
       "      <td>0.36660783892748805</td>\n",
       "      <td>0.7408896341244766</td>\n",
       "      <td>0.974595742158203</td>\n",
       "      <td>0.9153501080031586</td>\n",
       "      <td>0.5771167374769913</td>\n",
       "      <td>0.7353658352429491</td>\n",
       "      <td>0.39174186510683295</td>\n",
       "      <td>0.1741492354027061</td>\n",
       "      <td>0.22367880443734056</td>\n",
       "      <td>0.2580095327345979</td>\n",
       "      <td>0.1284110374680938</td>\n",
       "      <td>0.8115760569595589</td>\n",
       "      <td>0.3331990124799651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.916347570830484</td>\n",
       "      <td>0.35865988583009467</td>\n",
       "      <td>0.7396819972334266</td>\n",
       "      <td>0.8564551935351906</td>\n",
       "      <td>0.6640499071866844</td>\n",
       "      <td>0.2050568565255697</td>\n",
       "      <td>0.8135555023523368</td>\n",
       "      <td>0.6009753900522574</td>\n",
       "      <td>0.1982599099907576</td>\n",
       "      <td>0.5339285664741924</td>\n",
       "      <td>0.7737371241302291</td>\n",
       "      <td>0.834379113777423</td>\n",
       "      <td>0.09939726208635036</td>\n",
       "      <td>0.776431952683744</td>\n",
       "      <td>0.5872984984583752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.05822166399082185</td>\n",
       "      <td>0.5471829650136312</td>\n",
       "      <td>0.9557044545757675</td>\n",
       "      <td>0.3597201967060826</td>\n",
       "      <td>0.6811791990827586</td>\n",
       "      <td>0.8968355049267764</td>\n",
       "      <td>0.662054608256563</td>\n",
       "      <td>0.21923583930623824</td>\n",
       "      <td>0.031028046920852925</td>\n",
       "      <td>0.6978465276022923</td>\n",
       "      <td>0.9585795364026226</td>\n",
       "      <td>0.9614009181220384</td>\n",
       "      <td>0.12936519793070678</td>\n",
       "      <td>0.7724169792456678</td>\n",
       "      <td>0.5119660540732762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5576482040237595</td>\n",
       "      <td>0.624825641050446</td>\n",
       "      <td>0.7450517969908758</td>\n",
       "      <td>0.4360901603881916</td>\n",
       "      <td>0.5348912357886707</td>\n",
       "      <td>0.780279470772569</td>\n",
       "      <td>0.5473465659931593</td>\n",
       "      <td>0.268653928530702</td>\n",
       "      <td>0.038584290715249825</td>\n",
       "      <td>0.2627234004400495</td>\n",
       "      <td>0.07793960919419696</td>\n",
       "      <td>0.3562100200434195</td>\n",
       "      <td>0.8436402485400986</td>\n",
       "      <td>0.8911406608483197</td>\n",
       "      <td>0.7929452029028426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.7853729187976306</td>\n",
       "      <td>0.4026905959644621</td>\n",
       "      <td>0.7829248320505745</td>\n",
       "      <td>0.21299767741561093</td>\n",
       "      <td>0.8495725344127268</td>\n",
       "      <td>0.15253912684454307</td>\n",
       "      <td>0.5848199033249691</td>\n",
       "      <td>0.8953998638397274</td>\n",
       "      <td>0.8414331019601838</td>\n",
       "      <td>0.10784169274033018</td>\n",
       "      <td>0.9269870178680651</td>\n",
       "      <td>0.17497085635633713</td>\n",
       "      <td>0.030060779795877623</td>\n",
       "      <td>0.17117375544351965</td>\n",
       "      <td>0.8773033433696605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.253140019910315</td>\n",
       "      <td>0.8563302868270939</td>\n",
       "      <td>0.5767757914440819</td>\n",
       "      <td>0.5397708494320654</td>\n",
       "      <td>0.35635381152767276</td>\n",
       "      <td>0.06646713198612075</td>\n",
       "      <td>0.2535816555980206</td>\n",
       "      <td>0.7983794245614487</td>\n",
       "      <td>0.6137716793148283</td>\n",
       "      <td>0.2564921556115426</td>\n",
       "      <td>0.2960965511916498</td>\n",
       "      <td>0.7647106101571216</td>\n",
       "      <td>0.7119502377806182</td>\n",
       "      <td>0.5803673525091485</td>\n",
       "      <td>0.12795955018873062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.06179647970981317</td>\n",
       "      <td>0.6702611151232815</td>\n",
       "      <td>0.7435011464756542</td>\n",
       "      <td>0.3992640991433607</td>\n",
       "      <td>0.47614912131069764</td>\n",
       "      <td>0.4936155296205611</td>\n",
       "      <td>0.3283267716221735</td>\n",
       "      <td>0.794167887222117</td>\n",
       "      <td>0.1546635120481552</td>\n",
       "      <td>0.08795577528975673</td>\n",
       "      <td>0.9241497877957248</td>\n",
       "      <td>0.8790058910450617</td>\n",
       "      <td>0.4590267849420825</td>\n",
       "      <td>0.5061920543409153</td>\n",
       "      <td>0.4225601016759244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.5385437804954528</td>\n",
       "      <td>0.38274437456242705</td>\n",
       "      <td>0.2024152665769594</td>\n",
       "      <td>0.39164615711685713</td>\n",
       "      <td>0.6841067521059213</td>\n",
       "      <td>0.7519684836150099</td>\n",
       "      <td>0.6064088909104932</td>\n",
       "      <td>0.5102209646337809</td>\n",
       "      <td>0.6784810082278546</td>\n",
       "      <td>0.4790119285637733</td>\n",
       "      <td>0.8946537985765654</td>\n",
       "      <td>0.35021551517404137</td>\n",
       "      <td>0.4694878239940524</td>\n",
       "      <td>0.41162792882087706</td>\n",
       "      <td>0.1103233492305099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.07801589030150557</td>\n",
       "      <td>0.9262243196197725</td>\n",
       "      <td>0.49869794748215157</td>\n",
       "      <td>0.7866007454710502</td>\n",
       "      <td>0.838572046533248</td>\n",
       "      <td>0.06074472198919634</td>\n",
       "      <td>0.9771610235903299</td>\n",
       "      <td>0.31404192640073403</td>\n",
       "      <td>0.06517202770280783</td>\n",
       "      <td>0.8141575390239156</td>\n",
       "      <td>0.9420602694005984</td>\n",
       "      <td>0.3903858837245282</td>\n",
       "      <td>0.2518131402844883</td>\n",
       "      <td>0.383510172843357</td>\n",
       "      <td>0.37847785399698664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     x1                   x2                    x3  \\\n",
       "0    0.7279463652879037   0.6866263027974453  0.024216355151086222   \n",
       "1    0.9410291805105507   0.7548015847155811   0.36660783892748805   \n",
       "2     0.916347570830484  0.35865988583009467    0.7396819972334266   \n",
       "3   0.05822166399082185   0.5471829650136312    0.9557044545757675   \n",
       "4    0.5576482040237595    0.624825641050446    0.7450517969908758   \n",
       "..                  ...                  ...                   ...   \n",
       "95   0.7853729187976306   0.4026905959644621    0.7829248320505745   \n",
       "96    0.253140019910315   0.8563302868270939    0.5767757914440819   \n",
       "97  0.06179647970981317   0.6702611151232815    0.7435011464756542   \n",
       "98   0.5385437804954528  0.38274437456242705    0.2024152665769594   \n",
       "99  0.07801589030150557   0.9262243196197725   0.49869794748215157   \n",
       "\n",
       "                     x4                   x5                   x6  \\\n",
       "0   0.10051346797223315  0.14790184117738137   0.6651574435679946   \n",
       "1    0.7408896341244766    0.974595742158203   0.9153501080031586   \n",
       "2    0.8564551935351906   0.6640499071866844   0.2050568565255697   \n",
       "3    0.3597201967060826   0.6811791990827586   0.8968355049267764   \n",
       "4    0.4360901603881916   0.5348912357886707    0.780279470772569   \n",
       "..                  ...                  ...                  ...   \n",
       "95  0.21299767741561093   0.8495725344127268  0.15253912684454307   \n",
       "96   0.5397708494320654  0.35635381152767276  0.06646713198612075   \n",
       "97   0.3992640991433607  0.47614912131069764   0.4936155296205611   \n",
       "98  0.39164615711685713   0.6841067521059213   0.7519684836150099   \n",
       "99   0.7866007454710502    0.838572046533248  0.06074472198919634   \n",
       "\n",
       "                    x7                   x8                    x9  \\\n",
       "0   0.8865782074527322   0.2602098404854192    0.9135359850986395   \n",
       "1   0.5771167374769913   0.7353658352429491   0.39174186510683295   \n",
       "2   0.8135555023523368   0.6009753900522574    0.1982599099907576   \n",
       "3    0.662054608256563  0.21923583930623824  0.031028046920852925   \n",
       "4   0.5473465659931593    0.268653928530702  0.038584290715249825   \n",
       "..                 ...                  ...                   ...   \n",
       "95  0.5848199033249691   0.8953998638397274    0.8414331019601838   \n",
       "96  0.2535816555980206   0.7983794245614487    0.6137716793148283   \n",
       "97  0.3283267716221735    0.794167887222117    0.1546635120481552   \n",
       "98  0.6064088909104932   0.5102209646337809    0.6784810082278546   \n",
       "99  0.9771610235903299  0.31404192640073403   0.06517202770280783   \n",
       "\n",
       "                    x10                  x11                  x12  \\\n",
       "0     0.429280624808031   0.3863064875506751   0.4297454335327542   \n",
       "1    0.1741492354027061  0.22367880443734056   0.2580095327345979   \n",
       "2    0.5339285664741924   0.7737371241302291    0.834379113777423   \n",
       "3    0.6978465276022923   0.9585795364026226   0.9614009181220384   \n",
       "4    0.2627234004400495  0.07793960919419696   0.3562100200434195   \n",
       "..                  ...                  ...                  ...   \n",
       "95  0.10784169274033018   0.9269870178680651  0.17497085635633713   \n",
       "96   0.2564921556115426   0.2960965511916498   0.7647106101571216   \n",
       "97  0.08795577528975673   0.9241497877957248   0.8790058910450617   \n",
       "98   0.4790119285637733   0.8946537985765654  0.35021551517404137   \n",
       "99   0.8141575390239156   0.9420602694005984   0.3903858837245282   \n",
       "\n",
       "                     x13                  x14                  x15  \n",
       "0     0.3430209147301143   0.8642878816290207   0.6974519811249746  \n",
       "1     0.1284110374680938   0.8115760569595589   0.3331990124799651  \n",
       "2    0.09939726208635036    0.776431952683744   0.5872984984583752  \n",
       "3    0.12936519793070678   0.7724169792456678   0.5119660540732762  \n",
       "4     0.8436402485400986   0.8911406608483197   0.7929452029028426  \n",
       "..                   ...                  ...                  ...  \n",
       "95  0.030060779795877623  0.17117375544351965   0.8773033433696605  \n",
       "96    0.7119502377806182   0.5803673525091485  0.12795955018873062  \n",
       "97    0.4590267849420825   0.5061920543409153   0.4225601016759244  \n",
       "98    0.4694878239940524  0.41162792882087706   0.1103233492305099  \n",
       "99    0.2518131402844883    0.383510172843357  0.37847785399698664  \n",
       "\n",
       "[100 rows x 15 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data untuk prediksi\n",
    "df2 = pd.read_csv(\"UTS_test_soal.csv\", decimal = ',')\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "8f0bf0fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>x14</th>\n",
       "      <th>x15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.727946</td>\n",
       "      <td>0.686626</td>\n",
       "      <td>0.024216</td>\n",
       "      <td>0.100513</td>\n",
       "      <td>0.147902</td>\n",
       "      <td>0.665157</td>\n",
       "      <td>0.886578</td>\n",
       "      <td>0.260210</td>\n",
       "      <td>0.913536</td>\n",
       "      <td>0.429281</td>\n",
       "      <td>0.386306</td>\n",
       "      <td>0.429745</td>\n",
       "      <td>0.343021</td>\n",
       "      <td>0.864288</td>\n",
       "      <td>0.697452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.941029</td>\n",
       "      <td>0.754802</td>\n",
       "      <td>0.366608</td>\n",
       "      <td>0.740890</td>\n",
       "      <td>0.974596</td>\n",
       "      <td>0.915350</td>\n",
       "      <td>0.577117</td>\n",
       "      <td>0.735366</td>\n",
       "      <td>0.391742</td>\n",
       "      <td>0.174149</td>\n",
       "      <td>0.223679</td>\n",
       "      <td>0.258010</td>\n",
       "      <td>0.128411</td>\n",
       "      <td>0.811576</td>\n",
       "      <td>0.333199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.916348</td>\n",
       "      <td>0.358660</td>\n",
       "      <td>0.739682</td>\n",
       "      <td>0.856455</td>\n",
       "      <td>0.664050</td>\n",
       "      <td>0.205057</td>\n",
       "      <td>0.813556</td>\n",
       "      <td>0.600975</td>\n",
       "      <td>0.198260</td>\n",
       "      <td>0.533929</td>\n",
       "      <td>0.773737</td>\n",
       "      <td>0.834379</td>\n",
       "      <td>0.099397</td>\n",
       "      <td>0.776432</td>\n",
       "      <td>0.587298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.058222</td>\n",
       "      <td>0.547183</td>\n",
       "      <td>0.955704</td>\n",
       "      <td>0.359720</td>\n",
       "      <td>0.681179</td>\n",
       "      <td>0.896836</td>\n",
       "      <td>0.662055</td>\n",
       "      <td>0.219236</td>\n",
       "      <td>0.031028</td>\n",
       "      <td>0.697847</td>\n",
       "      <td>0.958580</td>\n",
       "      <td>0.961401</td>\n",
       "      <td>0.129365</td>\n",
       "      <td>0.772417</td>\n",
       "      <td>0.511966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.557648</td>\n",
       "      <td>0.624826</td>\n",
       "      <td>0.745052</td>\n",
       "      <td>0.436090</td>\n",
       "      <td>0.534891</td>\n",
       "      <td>0.780279</td>\n",
       "      <td>0.547347</td>\n",
       "      <td>0.268654</td>\n",
       "      <td>0.038584</td>\n",
       "      <td>0.262723</td>\n",
       "      <td>0.077940</td>\n",
       "      <td>0.356210</td>\n",
       "      <td>0.843640</td>\n",
       "      <td>0.891141</td>\n",
       "      <td>0.792945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.785373</td>\n",
       "      <td>0.402691</td>\n",
       "      <td>0.782925</td>\n",
       "      <td>0.212998</td>\n",
       "      <td>0.849573</td>\n",
       "      <td>0.152539</td>\n",
       "      <td>0.584820</td>\n",
       "      <td>0.895400</td>\n",
       "      <td>0.841433</td>\n",
       "      <td>0.107842</td>\n",
       "      <td>0.926987</td>\n",
       "      <td>0.174971</td>\n",
       "      <td>0.030061</td>\n",
       "      <td>0.171174</td>\n",
       "      <td>0.877303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.253140</td>\n",
       "      <td>0.856330</td>\n",
       "      <td>0.576776</td>\n",
       "      <td>0.539771</td>\n",
       "      <td>0.356354</td>\n",
       "      <td>0.066467</td>\n",
       "      <td>0.253582</td>\n",
       "      <td>0.798379</td>\n",
       "      <td>0.613772</td>\n",
       "      <td>0.256492</td>\n",
       "      <td>0.296097</td>\n",
       "      <td>0.764711</td>\n",
       "      <td>0.711950</td>\n",
       "      <td>0.580367</td>\n",
       "      <td>0.127960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.061796</td>\n",
       "      <td>0.670261</td>\n",
       "      <td>0.743501</td>\n",
       "      <td>0.399264</td>\n",
       "      <td>0.476149</td>\n",
       "      <td>0.493616</td>\n",
       "      <td>0.328327</td>\n",
       "      <td>0.794168</td>\n",
       "      <td>0.154664</td>\n",
       "      <td>0.087956</td>\n",
       "      <td>0.924150</td>\n",
       "      <td>0.879006</td>\n",
       "      <td>0.459027</td>\n",
       "      <td>0.506192</td>\n",
       "      <td>0.422560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.538544</td>\n",
       "      <td>0.382744</td>\n",
       "      <td>0.202415</td>\n",
       "      <td>0.391646</td>\n",
       "      <td>0.684107</td>\n",
       "      <td>0.751968</td>\n",
       "      <td>0.606409</td>\n",
       "      <td>0.510221</td>\n",
       "      <td>0.678481</td>\n",
       "      <td>0.479012</td>\n",
       "      <td>0.894654</td>\n",
       "      <td>0.350216</td>\n",
       "      <td>0.469488</td>\n",
       "      <td>0.411628</td>\n",
       "      <td>0.110323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.078016</td>\n",
       "      <td>0.926224</td>\n",
       "      <td>0.498698</td>\n",
       "      <td>0.786601</td>\n",
       "      <td>0.838572</td>\n",
       "      <td>0.060745</td>\n",
       "      <td>0.977161</td>\n",
       "      <td>0.314042</td>\n",
       "      <td>0.065172</td>\n",
       "      <td>0.814158</td>\n",
       "      <td>0.942060</td>\n",
       "      <td>0.390386</td>\n",
       "      <td>0.251813</td>\n",
       "      <td>0.383510</td>\n",
       "      <td>0.378478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          x1        x2        x3        x4        x5        x6        x7  \\\n",
       "0   0.727946  0.686626  0.024216  0.100513  0.147902  0.665157  0.886578   \n",
       "1   0.941029  0.754802  0.366608  0.740890  0.974596  0.915350  0.577117   \n",
       "2   0.916348  0.358660  0.739682  0.856455  0.664050  0.205057  0.813556   \n",
       "3   0.058222  0.547183  0.955704  0.359720  0.681179  0.896836  0.662055   \n",
       "4   0.557648  0.624826  0.745052  0.436090  0.534891  0.780279  0.547347   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "95  0.785373  0.402691  0.782925  0.212998  0.849573  0.152539  0.584820   \n",
       "96  0.253140  0.856330  0.576776  0.539771  0.356354  0.066467  0.253582   \n",
       "97  0.061796  0.670261  0.743501  0.399264  0.476149  0.493616  0.328327   \n",
       "98  0.538544  0.382744  0.202415  0.391646  0.684107  0.751968  0.606409   \n",
       "99  0.078016  0.926224  0.498698  0.786601  0.838572  0.060745  0.977161   \n",
       "\n",
       "          x8        x9       x10       x11       x12       x13       x14  \\\n",
       "0   0.260210  0.913536  0.429281  0.386306  0.429745  0.343021  0.864288   \n",
       "1   0.735366  0.391742  0.174149  0.223679  0.258010  0.128411  0.811576   \n",
       "2   0.600975  0.198260  0.533929  0.773737  0.834379  0.099397  0.776432   \n",
       "3   0.219236  0.031028  0.697847  0.958580  0.961401  0.129365  0.772417   \n",
       "4   0.268654  0.038584  0.262723  0.077940  0.356210  0.843640  0.891141   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "95  0.895400  0.841433  0.107842  0.926987  0.174971  0.030061  0.171174   \n",
       "96  0.798379  0.613772  0.256492  0.296097  0.764711  0.711950  0.580367   \n",
       "97  0.794168  0.154664  0.087956  0.924150  0.879006  0.459027  0.506192   \n",
       "98  0.510221  0.678481  0.479012  0.894654  0.350216  0.469488  0.411628   \n",
       "99  0.314042  0.065172  0.814158  0.942060  0.390386  0.251813  0.383510   \n",
       "\n",
       "         x15  \n",
       "0   0.697452  \n",
       "1   0.333199  \n",
       "2   0.587298  \n",
       "3   0.511966  \n",
       "4   0.792945  \n",
       "..       ...  \n",
       "95  0.877303  \n",
       "96  0.127960  \n",
       "97  0.422560  \n",
       "98  0.110323  \n",
       "99  0.378478  \n",
       "\n",
       "[100 rows x 15 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merubah tipe data yang ada di dataset menjadi float\n",
    "df2 = df2.astype(float)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "37a623ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "#melakukan prediksi\n",
    "data_pred = df2.values\n",
    "\n",
    "y_pred = model.predict(data_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "3c8d94e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.5275776 ],\n",
       "       [ 1.8633405 ],\n",
       "       [10.260366  ],\n",
       "       [ 7.8072786 ],\n",
       "       [ 1.1341385 ],\n",
       "       [ 2.9997013 ],\n",
       "       [ 0.47767255],\n",
       "       [ 4.249479  ],\n",
       "       [ 8.45704   ],\n",
       "       [ 2.0621955 ],\n",
       "       [ 2.754345  ],\n",
       "       [ 2.9217713 ],\n",
       "       [ 6.3823223 ],\n",
       "       [-3.9113708 ],\n",
       "       [ 8.04449   ],\n",
       "       [ 6.028364  ],\n",
       "       [ 7.443757  ],\n",
       "       [ 9.380542  ],\n",
       "       [ 9.029438  ],\n",
       "       [-0.86473256],\n",
       "       [ 6.7097692 ],\n",
       "       [ 1.235998  ],\n",
       "       [-0.53864485],\n",
       "       [-3.7897825 ],\n",
       "       [ 1.7245727 ],\n",
       "       [-1.3688967 ],\n",
       "       [ 2.7086613 ],\n",
       "       [ 0.804797  ],\n",
       "       [ 0.2590579 ],\n",
       "       [ 4.083829  ],\n",
       "       [10.098522  ],\n",
       "       [ 8.532601  ],\n",
       "       [ 2.3419528 ],\n",
       "       [10.326538  ],\n",
       "       [ 7.5166435 ],\n",
       "       [ 4.6440406 ],\n",
       "       [ 4.5556445 ],\n",
       "       [-0.08066811],\n",
       "       [ 5.7969627 ],\n",
       "       [-4.2184772 ],\n",
       "       [ 4.4511194 ],\n",
       "       [ 7.1802654 ],\n",
       "       [ 7.206217  ],\n",
       "       [ 7.1709127 ],\n",
       "       [-0.44536397],\n",
       "       [ 2.5975401 ],\n",
       "       [ 0.04723589],\n",
       "       [ 5.5476713 ],\n",
       "       [-0.34264332],\n",
       "       [-0.26532343],\n",
       "       [ 0.06112562],\n",
       "       [ 1.8346034 ],\n",
       "       [ 5.054782  ],\n",
       "       [ 5.4229198 ],\n",
       "       [ 4.7549706 ],\n",
       "       [-4.181343  ],\n",
       "       [ 6.2503324 ],\n",
       "       [ 7.011168  ],\n",
       "       [ 5.447226  ],\n",
       "       [-0.1218456 ],\n",
       "       [ 8.6773815 ],\n",
       "       [ 5.56486   ],\n",
       "       [ 4.8620043 ],\n",
       "       [ 9.61915   ],\n",
       "       [ 2.175234  ],\n",
       "       [ 7.2207694 ],\n",
       "       [ 7.1668816 ],\n",
       "       [ 3.973547  ],\n",
       "       [ 1.6005095 ],\n",
       "       [ 5.0672545 ],\n",
       "       [ 6.995069  ],\n",
       "       [-0.98426104],\n",
       "       [ 4.5591416 ],\n",
       "       [ 1.1353164 ],\n",
       "       [-0.7960085 ],\n",
       "       [ 8.180097  ],\n",
       "       [ 2.864633  ],\n",
       "       [ 1.5438162 ],\n",
       "       [ 0.11356245],\n",
       "       [ 4.7334204 ],\n",
       "       [10.850047  ],\n",
       "       [ 1.7634503 ],\n",
       "       [ 3.3966203 ],\n",
       "       [ 7.385454  ],\n",
       "       [ 3.9534125 ],\n",
       "       [ 2.7412527 ],\n",
       "       [ 8.658351  ],\n",
       "       [-0.932024  ],\n",
       "       [ 2.9148955 ],\n",
       "       [10.324841  ],\n",
       "       [ 4.746969  ],\n",
       "       [ 2.2850106 ],\n",
       "       [ 5.685617  ],\n",
       "       [ 6.1565976 ],\n",
       "       [ 8.617994  ],\n",
       "       [ 9.344347  ],\n",
       "       [ 0.12648782],\n",
       "       [ 7.246525  ],\n",
       "       [-0.24078622],\n",
       "       [ 6.1747565 ]], dtype=float32)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hasil prediks\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "bc29ef37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.5275776386260986,\n",
       " 1.8633404970169067,\n",
       " 10.260366439819336,\n",
       " 7.807278633117676,\n",
       " 1.1341384649276733,\n",
       " 2.9997012615203857,\n",
       " 0.4776725471019745,\n",
       " 4.249478816986084,\n",
       " 8.457039833068848,\n",
       " 2.0621955394744873,\n",
       " 2.754344940185547,\n",
       " 2.921771287918091,\n",
       " 6.382322311401367,\n",
       " -3.9113707542419434,\n",
       " 8.044489860534668,\n",
       " 6.028364181518555,\n",
       " 7.443757057189941,\n",
       " 9.380541801452637,\n",
       " 9.029438018798828,\n",
       " -0.864732563495636,\n",
       " 6.709769248962402,\n",
       " 1.2359980344772339,\n",
       " -0.5386448502540588,\n",
       " -3.7897825241088867,\n",
       " 1.7245726585388184,\n",
       " -1.368896722793579,\n",
       " 2.7086613178253174,\n",
       " 0.8047969937324524,\n",
       " 0.2590579092502594,\n",
       " 4.083828926086426,\n",
       " 10.098522186279297,\n",
       " 8.532601356506348,\n",
       " 2.3419528007507324,\n",
       " 10.3265380859375,\n",
       " 7.516643524169922,\n",
       " 4.644040584564209,\n",
       " 4.555644512176514,\n",
       " -0.08066810667514801,\n",
       " 5.796962738037109,\n",
       " -4.218477249145508,\n",
       " 4.451119422912598,\n",
       " 7.180265426635742,\n",
       " 7.206216812133789,\n",
       " 7.170912742614746,\n",
       " -0.44536396861076355,\n",
       " 2.5975401401519775,\n",
       " 0.0472358874976635,\n",
       " 5.547671318054199,\n",
       " -0.3426433205604553,\n",
       " -0.2653234302997589,\n",
       " 0.06112561747431755,\n",
       " 1.8346034288406372,\n",
       " 5.054781913757324,\n",
       " 5.422919750213623,\n",
       " 4.754970550537109,\n",
       " -4.181343078613281,\n",
       " 6.250332355499268,\n",
       " 7.011168003082275,\n",
       " 5.447226047515869,\n",
       " -0.12184560298919678,\n",
       " 8.67738151550293,\n",
       " 5.564859867095947,\n",
       " 4.862004280090332,\n",
       " 9.619150161743164,\n",
       " 2.175234079360962,\n",
       " 7.22076940536499,\n",
       " 7.166881561279297,\n",
       " 3.9735469818115234,\n",
       " 1.600509524345398,\n",
       " 5.067254543304443,\n",
       " 6.9950690269470215,\n",
       " -0.9842610359191895,\n",
       " 4.559141635894775,\n",
       " 1.1353163719177246,\n",
       " -0.7960085272789001,\n",
       " 8.180096626281738,\n",
       " 2.864633083343506,\n",
       " 1.5438162088394165,\n",
       " 0.1135624498128891,\n",
       " 4.733420372009277,\n",
       " 10.85004711151123,\n",
       " 1.763450264930725,\n",
       " 3.396620273590088,\n",
       " 7.385454177856445,\n",
       " 3.9534125328063965,\n",
       " 2.7412526607513428,\n",
       " 8.658350944519043,\n",
       " -0.9320240020751953,\n",
       " 2.914895534515381,\n",
       " 10.324840545654297,\n",
       " 4.746969223022461,\n",
       " 2.285010576248169,\n",
       " 5.685616970062256,\n",
       " 6.15659761428833,\n",
       " 8.61799430847168,\n",
       " 9.34434700012207,\n",
       " 0.1264878213405609,\n",
       " 7.246524810791016,\n",
       " -0.24078622460365295,\n",
       " 6.1747565269470215]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#menjadikan output prediksi menjadi list untuk membuat dataframe output\n",
    "konv = y_pred.tolist()\n",
    "konv = [konv[i][0] for i in range(len(konv))]\n",
    "\n",
    "konv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "9ad16633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.527578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.863340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.260366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.807279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.134138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>9.344347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.126488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>7.246525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-0.240786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>6.174757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y\n",
       "0    3.527578\n",
       "1    1.863340\n",
       "2   10.260366\n",
       "3    7.807279\n",
       "4    1.134138\n",
       "..        ...\n",
       "95   9.344347\n",
       "96   0.126488\n",
       "97   7.246525\n",
       "98  -0.240786\n",
       "99   6.174757\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# menjadikan output menjadi dataframe\n",
    "hasil = pd.DataFrame({\"y\":konv})\n",
    "\n",
    "hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c5e86893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export hasil prediksi\n",
    "hasil.to_csv(\"20102153.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
